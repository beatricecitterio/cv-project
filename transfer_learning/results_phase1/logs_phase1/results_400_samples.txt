
=== Starting Transfer Learning Pipeline with 400 labeled samples ===
Of these, 281 have known labels and will be used for training

=== Preparing Data for Training ===
Training set: 216 images
Validation set: 73 images
Dataset created with 216 images and 41 classes
Class mapping: {'arg-col': 0, 'arg-par': 1, 'aus-ger': 2, 'bra-ger': 3, 'bra-par': 4, 'chi-per': 5, 'civ-gha': 6, 'civ.gha': 7, 'cod-eqg': 8, 'cri-cie': 9, 'cro-por': 10, 'cry-mnu': 11, 'egy-swe': 12, 'eng-bra': 13, 'eng-ice': 14, 'eng-isl': 15, 'eng-rus': 16, 'eng-wal': 17, 'eqg-cgo': 18, 'esp-uru': 19, 'fra-eng': 20, 'ger-fra': 21, 'ger-svk': 22, 'ger-swe': 23, 'hun-bel': 24, 'irn-irq': 25, 'irq-uae': 26, 'isl-aut': 27, 'isl-hun': 28, 'ita-roi': 29, 'kor-irq': 30, 'mci-eve': 31, 'per-par': 32, 'rou-alb': 33, 'ste-gaz': 34, 'svk-eng': 35, 'swa-mun': 36, 'tot-che': 37, 'tun-cpv': 38, 'wal-nir': 39, 'zam-cod': 40}
Dataset created with 73 images and 41 classes
Class mapping: {'arg-col': 0, 'arg-par': 1, 'aus-ger': 2, 'bra-ger': 3, 'bra-par': 4, 'chi-per': 5, 'civ-gha': 6, 'civ.gha': 7, 'cod-eqg': 8, 'cri-cie': 9, 'cro-por': 10, 'cry-mnu': 11, 'egy-swe': 12, 'eng-bra': 13, 'eng-ice': 14, 'eng-isl': 15, 'eng-rus': 16, 'eng-wal': 17, 'eqg-cgo': 18, 'esp-uru': 19, 'fra-eng': 20, 'ger-fra': 21, 'ger-svk': 22, 'ger-swe': 23, 'hun-bel': 24, 'irn-irq': 25, 'irq-uae': 26, 'isl-aut': 27, 'isl-hun': 28, 'ita-roi': 29, 'kor-irq': 30, 'mci-eve': 31, 'per-par': 32, 'rou-alb': 33, 'ste-gaz': 34, 'svk-eng': 35, 'swa-mun': 36, 'tot-che': 37, 'tun-cpv': 38, 'wal-nir': 39, 'zam-cod': 40}

=== Training Transfer Learning Model ===
Class names: ['arg-col', 'arg-par', 'aus-ger', 'bra-ger', 'bra-par', 'chi-per', 'civ-gha', 'civ.gha', 'cod-eqg', 'cri-cie', 'cro-por', 'cry-mnu', 'egy-swe', 'eng-bra', 'eng-ice', 'eng-isl', 'eng-rus', 'eng-wal', 'eqg-cgo', 'esp-uru', 'fra-eng', 'ger-fra', 'ger-svk', 'ger-swe', 'hun-bel', 'irn-irq', 'irq-uae', 'isl-aut', 'isl-hun', 'ita-roi', 'kor-irq', 'mci-eve', 'per-par', 'rou-alb', 'ste-gaz', 'svk-eng', 'swa-mun', 'tot-che', 'tun-cpv', 'wal-nir', 'zam-cod']
Number of classes: 41
Using device: cuda:0

Training Progress:
----------------------------------------------------------------------
  Epoch   |  Train Loss   |   Train Acc   |   Val Loss    |    Val Acc    
----------------------------------------------------------------------
    1     |    3.7747     |    0.0417     |    3.6846     |    0.0274     
    2     |    3.4425     |    0.1204     |    3.4494     |    0.1233     
    3     |    3.2359     |    0.1574     |    3.2451     |    0.1918     
    4     |    3.0977     |    0.1759     |    3.0169     |    0.2192     
    5     |    2.7566     |    0.3056     |    2.8620     |    0.2877     
    6     |    2.5869     |    0.3565     |    2.7863     |    0.2740     
    7     |    2.4567     |    0.3796     |    2.5855     |    0.3562     
    8     |    2.2013     |    0.5370     |    2.5236     |    0.3836     
    9     |    2.1429     |    0.5787     |    2.5335     |    0.3562     
    10    |    2.1117     |    0.5509     |    2.4695     |    0.3973     
    11    |    2.1078     |    0.5972     |    2.4597     |    0.4247     
    12    |    2.0637     |    0.5972     |    2.4655     |    0.3425     
    13    |    2.0138     |    0.5880     |    2.4522     |    0.3973     
    14    |    2.0226     |    0.5972     |    2.4610     |    0.3562     
    15    |    1.9864     |    0.6019     |    2.4461     |    0.3973     
----------------------------------------------------------------------
Training complete in 0m 30s
Best val Acc: 0.4247
Model saved as 'model_400_samples.pth'

=== Performing Inference on Unlabeled Images ===
Found 9600 unlabeled images for inference
Average confidence on unlabeled images: 0.1991
Adding 33 high-confidence predictions to auto-labeled set

=== Extracting Samples by Confidence ===

Top 20 most confident predictions:
  42030.jpg: tun-cpv (confidence: 0.9423)
  42029.jpg: tun-cpv (confidence: 0.9343)
  42033.jpg: tun-cpv (confidence: 0.9299)
  42032.jpg: tun-cpv (confidence: 0.9281)
  80978.jpg: kor-irq (confidence: 0.9279)
  42037.jpg: tun-cpv (confidence: 0.9176)
  78609.jpg: irn-irq (confidence: 0.9127)
  42352.jpg: tun-cpv (confidence: 0.9113)
  42034.jpg: tun-cpv (confidence: 0.9108)
  42832.jpg: tun-cpv (confidence: 0.9096)
  54216.jpg: eng-wal (confidence: 0.9080)
  42031.jpg: tun-cpv (confidence: 0.9074)
  13511.jpg: rou-alb (confidence: 0.9024)
  13612.jpg: rou-alb (confidence: 0.9017)
  42035.jpg: tun-cpv (confidence: 0.8940)
  42039.jpg: tun-cpv (confidence: 0.8937)
  42314.jpg: tun-cpv (confidence: 0.8926)
  13602.jpg: rou-alb (confidence: 0.8905)
  78613.jpg: irn-irq (confidence: 0.8801)
  77845.jpg: irn-irq (confidence: 0.8753)

Selected 100 least confident images for labeling

Saved most confident predictions to 'most_confident_400_samples.csv'
Emptying directory: data/samples_to_label
Emptied directory: data/samples_to_label
Copied 0 least confident samples to 'data/samples_to_label' directory (for blind labeling)

=== Process Complete ===
Training completed with 400 labeled samples
Best validation accuracy: 0.4247
You can now manually label the images in 'data/samples_to_label' (blind labeling)
Average confidence on unlabeled images: 0.1991
