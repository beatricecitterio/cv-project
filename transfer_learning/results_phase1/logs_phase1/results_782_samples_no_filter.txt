
=== Starting Transfer Learning Pipeline with 782 labeled samples ===
Of these, 601 have known labels and will be used for training

=== Preparing Data for Training ===
Training set: 467 images
Validation set: 140 images
Dataset created with 467 images and 42 classes
Class mapping: {'arg-col': 0, 'arg-par': 1, 'aus-ger': 2, 'bra-ger': 3, 'bra-par': 4, 'chi-per': 5, 'civ-gha': 6, 'civ.gha': 7, 'cod-eqg': 8, 'cri-cie': 9, 'cro-por': 10, 'cry-mnu': 11, 'egy-swe': 12, 'eng-bra': 13, 'eng-ice': 14, 'eng-isl': 15, 'eng-rus': 16, 'eng-wal': 17, 'eqg-cgo': 18, 'esp-uru': 19, 'fra-eng': 20, 'ger-fra': 21, 'ger-svk': 22, 'ger-swe': 23, 'hun-bel': 24, 'irn-irq': 25, 'irq-uae': 26, 'isl-aut': 27, 'isl-hun': 28, 'ita-roi': 29, 'kor-irq': 30, 'mci-eve': 31, 'per-par': 32, 'pol-fra': 33, 'rou-alb': 34, 'ste-gaz': 35, 'svk-eng': 36, 'swa-mun': 37, 'tot-che': 38, 'tun-cpv': 39, 'wal-nir': 40, 'zam-cod': 41}
Dataset created with 140 images and 42 classes
Class mapping: {'arg-col': 0, 'arg-par': 1, 'aus-ger': 2, 'bra-ger': 3, 'bra-par': 4, 'chi-per': 5, 'civ-gha': 6, 'civ.gha': 7, 'cod-eqg': 8, 'cri-cie': 9, 'cro-por': 10, 'cry-mnu': 11, 'egy-swe': 12, 'eng-bra': 13, 'eng-ice': 14, 'eng-isl': 15, 'eng-rus': 16, 'eng-wal': 17, 'eqg-cgo': 18, 'esp-uru': 19, 'fra-eng': 20, 'ger-fra': 21, 'ger-svk': 22, 'ger-swe': 23, 'hun-bel': 24, 'irn-irq': 25, 'irq-uae': 26, 'isl-aut': 27, 'isl-hun': 28, 'ita-roi': 29, 'kor-irq': 30, 'mci-eve': 31, 'per-par': 32, 'pol-fra': 33, 'rou-alb': 34, 'ste-gaz': 35, 'svk-eng': 36, 'swa-mun': 37, 'tot-che': 38, 'tun-cpv': 39, 'wal-nir': 40, 'zam-cod': 41}

=== Training Transfer Learning Model ===
Class names: ['arg-col', 'arg-par', 'aus-ger', 'bra-ger', 'bra-par', 'chi-per', 'civ-gha', 'civ.gha', 'cod-eqg', 'cri-cie', 'cro-por', 'cry-mnu', 'egy-swe', 'eng-bra', 'eng-ice', 'eng-isl', 'eng-rus', 'eng-wal', 'eqg-cgo', 'esp-uru', 'fra-eng', 'ger-fra', 'ger-svk', 'ger-swe', 'hun-bel', 'irn-irq', 'irq-uae', 'isl-aut', 'isl-hun', 'ita-roi', 'kor-irq', 'mci-eve', 'per-par', 'pol-fra', 'rou-alb', 'ste-gaz', 'svk-eng', 'swa-mun', 'tot-che', 'tun-cpv', 'wal-nir', 'zam-cod']
Number of classes: 42
Using device: cuda:0

Training Progress:
----------------------------------------------------------------------
  Epoch   |  Train Loss   |   Train Acc   |   Val Loss    |    Val Acc    
----------------------------------------------------------------------
    1     |    3.1674     |    0.2698     |    2.8122     |    0.3000     
    2     |    2.5991     |    0.3790     |    2.5460     |    0.3857     
    3     |    2.3473     |    0.4304     |    2.3100     |    0.4571     
    4     |    2.1388     |    0.4775     |    2.2461     |    0.4500     
    5     |    2.0351     |    0.4882     |    2.1254     |    0.4714     
    6     |    1.8223     |    0.5418     |    2.0887     |    0.4643     
    7     |    1.7120     |    0.5717     |    1.9595     |    0.5143     
    8     |    1.5089     |    0.6274     |    1.9147     |    0.5286     
    9     |    1.4853     |    0.6274     |    1.9015     |    0.5214     
    10    |    1.4351     |    0.6788     |    1.9001     |    0.5357     
    11    |    1.4948     |    0.6317     |    1.8686     |    0.5643     
    12    |    1.4824     |    0.6831     |    1.8838     |    0.5357     
    13    |    1.4403     |    0.6938     |    1.8763     |    0.5643     
    14    |    1.4344     |    0.6702     |    1.8600     |    0.5500     
    15    |    1.4037     |    0.6874     |    1.8547     |    0.5571     
----------------------------------------------------------------------
Training complete in 0m 58s
Best val Acc: 0.5643
Model saved as 'model_782_samples.pth'

=== Performing Inference on Unlabeled Images ===
Found 9218 unlabeled images for inference
Average confidence on unlabeled images: 0.2626
Adding 152 high-confidence predictions to auto-labeled set

=== Extracting Samples by Confidence ===

Top 20 most confident predictions:
  42695.jpg: tun-cpv (confidence: 0.9974)
  42706.jpg: tun-cpv (confidence: 0.9972)
  42829.jpg: tun-cpv (confidence: 0.9971)
  44379.jpg: tun-cpv (confidence: 0.9958)
  41675.jpg: tun-cpv (confidence: 0.9935)
  42702.jpg: tun-cpv (confidence: 0.9920)
  42831.jpg: tun-cpv (confidence: 0.9918)
  41927.jpg: tun-cpv (confidence: 0.9903)
  24600.jpg: tun-cpv (confidence: 0.9900)
  44185.jpg: tun-cpv (confidence: 0.9900)
  43632.jpg: tun-cpv (confidence: 0.9894)
  44184.jpg: tun-cpv (confidence: 0.9891)
  44241.jpg: tun-cpv (confidence: 0.9885)
  41678.jpg: tun-cpv (confidence: 0.9883)
  24561.jpg: tun-cpv (confidence: 0.9874)
  43639.jpg: tun-cpv (confidence: 0.9867)
  42811.jpg: tun-cpv (confidence: 0.9847)
  44186.jpg: tun-cpv (confidence: 0.9811)
  43635.jpg: tun-cpv (confidence: 0.9779)
  47198.jpg: civ-gha (confidence: 0.9765)

Selected 100 least confident images for labeling

Saved most confident predictions to 'most_confident_782_samples.csv'
Emptying directory: data/samples_to_label
Emptied directory: data/samples_to_label
Copied 100 least confident samples to 'data/samples_to_label' directory (for blind labeling)

=== Process Complete ===
Training completed with 782 labeled samples
Best validation accuracy: 0.5643
You can now manually label the images in 'data/samples_to_label' (blind labeling)
Average confidence on unlabeled images: 0.2626
